# Defining and documenting elements of the world

## Inspecting the world
The recommended approach is spectator navigation, but as far as I can tell, that's a different mental model for runpod (more of a remote desktop). 

Using script-based approaches is the more direct path for now.

Here's what I have so far:
```
Map: Carla/Maps/Town10HD_Opt
Synchronous mode: False
Fixed delta seconds: None

Weather:
  Cloudiness: 20.0
  Precipitation: 0.0
  Sun altitude angle: 45.0

Actors:
  Vehicles: 0
  Walkers: 0
  Sensors: 0
  Traffic lights: 15

Spawn points available: 155
```

And inspecting the world at the end of the previous rendering stack, we see `Vehicles: 1` and `Sensors: 4` as expected.

```
Map: Carla/Maps/Town10HD_Opt
Synchronous mode: True
Fixed delta seconds: 0.1

Weather:
  Cloudiness: 20.0
  Precipitation: 0.0
  Sun altitude angle: 45.0

Actors:
  Vehicles: 1
  Walkers: 0
  Sensors: 4
  Traffic lights: 15

Spawn points available: 155
```

## Variations on weather
Changing the position of the sun is a simple test.

Here's a recording from the front_wide RGB camera, while we update the world.
![front main](../data/illustrations/sunset.gif)

It's interesting to note that frame 45 (0 degrees) is when ALL lights turn on. It's good to see that, although as far as ChatGPT can tell I'd need to dig into the unreal settings to get a more realistic behaviour (with only some lights turning on gradually during twilight).